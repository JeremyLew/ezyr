[{"path":"https://jeremylew.github.io/ezyr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 ezyr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jeremylew.github.io/ezyr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jeremy Lew. Author, maintainer.","code":""},{"path":"https://jeremylew.github.io/ezyr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lew J (2024). ezyr: Helper Function Toolkit Makes Data Operations Easier. R package version 0.0.0.9000, https://jeremylew.github.io/ezyr/.","code":"@Manual{,   title = {ezyr: Helper Function Toolkit That Makes Data Operations Easier},   author = {Jeremy Lew},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://jeremylew.github.io/ezyr/}, }"},{"path":"https://jeremylew.github.io/ezyr/index.html","id":"ezyr","dir":"","previous_headings":"","what":"Helper Function Toolkit That Makes Data Operations Easier","title":"Helper Function Toolkit That Makes Data Operations Easier","text":"package toolkit helper functions makes handling data presenting analyses easier (ezyr).","code":""},{"path":"https://jeremylew.github.io/ezyr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Helper Function Toolkit That Makes Data Operations Easier","text":"","code":"# First install devtools from CRAN install.packages(\"devtools\")  # Install ezyr from this github repository devtools::install_github(\"JeremyLew/ezyr\")"},{"path":"https://jeremylew.github.io/ezyr/reference/ask_for_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Ask for passkey — ask_for_key","title":"Ask for passkey — ask_for_key","text":"ask_for_key asks passkey used create sodium symmetric key (using cyphr::key_sodium) can used encrypt data using cyphr::encrypt.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ask_for_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ask for passkey — ask_for_key","text":"","code":"ask_for_key(key = NULL)"},{"path":"https://jeremylew.github.io/ezyr/reference/ask_for_key.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ask for passkey — ask_for_key","text":"key (character) passkey creating sodium key. Defaults NULL, user prompted passkey runtime via rstudioapi::askForPassword","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ask_for_key.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ask for passkey — ask_for_key","text":"(cyphr_key) sodium key encrypting data cyphr::encrypt","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ask_for_key.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ask for passkey — ask_for_key","text":"","code":"try(   if (!exists(\"key\")) {     key <- ask_for_key()     print(key)   } ) #> Error : RStudio not running"},{"path":"https://jeremylew.github.io/ezyr/reference/export_dataframe_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Export dataframe labels to excel — export_dataframe_labels","title":"Export dataframe labels to excel — export_dataframe_labels","text":"export_dataframe_labels exports variable labels dataframe, created labelled::var_label, excel sheet.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/export_dataframe_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export dataframe labels to excel — export_dataframe_labels","text":"","code":"export_dataframe_labels(   data,   workbook,   sheet_name = format(Sys.time(), \"%d%b%Y_%H%M\") )"},{"path":"https://jeremylew.github.io/ezyr/reference/export_dataframe_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export dataframe labels to excel — export_dataframe_labels","text":"data (data.frame) dataframe whose variable labels want export excel workbook (character) File path excel workbook sheet_name (character) Name excel sheet export labels Defaults system time execution none provided","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/export_dataframe_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export dataframe labels to excel — export_dataframe_labels","text":"None","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/export_dataframe_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export dataframe labels to excel — export_dataframe_labels","text":"","code":"library(labelled)  df <- data.frame(   column_a = sample(letters, 3),   column_b = runif(3, 1, 10) ) labels <- list(   column_a = \"This is column A\",   column_b = \"This is column B\" ) var_label(df) <- labels  # Export column labels to an excel file in temp directory output_filepath_1 <- file.path(tempdir(), \"file1.xlsx\") export_dataframe_labels(df, output_filepath_1, sheet_name = \"my_sheet\") print(list.files(tempdir(), pattern = \"\\\\.(xlsx|xls)$\")) #> [1] \"file1.xlsx\"  # Delete the excel file in temp directory unlink(output_filepath_1) print(list.files(tempdir(), pattern = \"\\\\.(xlsx|xls)$\")) #> character(0)"},{"path":"https://jeremylew.github.io/ezyr/reference/export_to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"Export to excel — export_to_excel","title":"Export to excel — export_to_excel","text":"export_to_excel enables export data excel workbook.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/export_to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export to excel — export_to_excel","text":"","code":"export_to_excel(   output_table,   workbook,   sheet_name = format(Sys.time(), \"%d%b%Y_%H%M\") )"},{"path":"https://jeremylew.github.io/ezyr/reference/export_to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export to excel — export_to_excel","text":"output_table (data.frame) Data want export excel workbook (character) File path excel workbook workbook exist, first created workbook exists, data exported specified sheet sheet_name (character) Name excel sheet export data Defaults system time execution none provided","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/export_to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export to excel — export_to_excel","text":"None","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/export_to_excel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export to excel — export_to_excel","text":"","code":"# Load data data(BostonHousing2, package = \"mlbench\")  # Export data to an excel file in temp directory output_filepath_1 <- file.path(tempdir(), \"file1.xlsx\") export_to_excel(BostonHousing2, output_filepath_1, sheet_name = \"my_sheet\") print(list.files(tempdir(), pattern = \"\\\\.(xlsx|xls)$\")) #> [1] \"file1.xlsx\"  # Delete the excel file in temp directory unlink(output_filepath_1) print(list.files(tempdir(), pattern = \"\\\\.(xlsx|xls)$\")) #> character(0)"},{"path":"https://jeremylew.github.io/ezyr/reference/extract_reading_from_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract latest reading in specified window period of observation — extract_reading_from_interval","title":"Extract latest reading in specified window period of observation — extract_reading_from_interval","text":"Suppose following, extract_reading_from_interval extract latest laboratory reading patient within respective window periods considered \"baseline\" reading, \"3-month\" reading etc. set longitudinal data e.g. laboratory readings patients set parameters define window period observation considering readings constitute \"baseline\" reading, \"3-month\" reading etc. example: baseline: T-180 days T 3-month: T+31 days T+90 days T index date enrolment date date first visit","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/extract_reading_from_interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract latest reading in specified window period of observation — extract_reading_from_interval","text":"","code":"extract_reading_from_interval(   df_master,   df_master_fields,   df_long,   df_long_fields,   params )"},{"path":"https://jeremylew.github.io/ezyr/reference/extract_reading_from_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract latest reading in specified window period of observation — extract_reading_from_interval","text":"df_master (data.frame) Master dataframe join readings unto. df_master must minimally contain following 2 columns: column IDs identify patient column index dates (refer T description ) patient columns identified df_master_fields df_master_fields (list) named list identify ID index date columns df_master takes format: list(ID = <your_ID_column>, index_date = <your_index_date_column>) example: list(ID = \"patient_id\", index_date = \"enrolment_date\") df_long (data.frame) Longitudinal data e.g. laboratory readings df_long_fields (list) named list identify reading date reading(s) df_long takes format: list(reading_date = <your_reading_date_column>, reading = <your_reading_column(s)>) reading_date (character) name dataframe column contains dates readings reading (character character vector) name(s) dataframe column(s) contains readings example: list(reading_date = \"calendar_date\", reading = c(\"bp_systolic\", \"bp_diastolic\")) params (list) named list names timepoints values numeric vectors represent c(lower_bound, upper_bound) example: params <- list(baseline = c(-180, 0), \"3mth\" = c(31, 90), \"6mth\" = c(120, 180)) lower upper bounds included defining window period .e. lower_bound <= reading_date <= upper_bound params given , extract_reading_from_interval consider Baseline reading: latest reading T-180 days <= reading_date <= T window 3-month reading: latest reading T+31 days <= reading_date <= T+90 days window 6-month reading: latest reading T+120 days <= reading_date <= T+180 days window","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/extract_reading_from_interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract latest reading in specified window period of observation — extract_reading_from_interval","text":"(data.frame) df_master longitudinal readings joined unto","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/extract_reading_from_interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract latest reading in specified window period of observation — extract_reading_from_interval","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  # Generate fake patient data for illustration ------------------------------- generate_fake_patient_data <- function(id) {   data.frame(     list(       patient_id = id,       enrolment_date = Sys.Date() + runif(1, min = -730, max = 0),       bp_systolic = sample(30:160, 9, replace = FALSE),       bp_diastolic = sample(10:100, 9, replace = FALSE),       hba1c = sample(4:14, 9, replace = FALSE)     ),     time = c(rep(\"baseline\", 3), rep(\"6mth\", 3), rep(\"12mth\", 3))   ) %>%     mutate(visit_date = case_when(       time == \"baseline\" ~ enrolment_date + sample(-180:0, 3, replace = FALSE),       time == \"6mth\" ~ enrolment_date + sample(100:180, 3, replace = FALSE),       time == \"12mth\" ~ enrolment_date + sample(240:360, 3, replace = FALSE)     ),     days_difference = visit_date - enrolment_date) %>%   relocate(enrolment_date, .after = visit_date) %>%   relocate(time, .after = days_difference) }  df_long <- rbind(   generate_fake_patient_data(\"P01\"),   generate_fake_patient_data(\"P02\"),   generate_fake_patient_data(\"P03\") ) %>%   dplyr::arrange(patient_id, visit_date)  # Master dataframe df_master <- df_long %>% distinct(patient_id, enrolment_date) print(df_master) #>   patient_id enrolment_date #> 1        P01     2023-06-13 #> 2        P02     2024-01-04 #> 3        P03     2023-06-23  # Longitudinal data of readings ## 1. days_difference = visit_date - enrolment_date ## 2. enrolment_date, days_difference and time are not required as input but ##    are shown for illustration purpose ## 3. enrolment_date will be joined unto df_long from df_master internally ## 4. days_difference will be computed internally print(df_long) #>    patient_id bp_systolic bp_diastolic hba1c visit_date enrolment_date #> 1         P01          34           52     5 2022-12-24     2023-06-13 #> 2         P01          76           71     7 2023-05-13     2023-06-13 #> 3         P01          53           14     6 2023-05-23     2023-06-13 #> 4         P01         106           53     9 2023-10-07     2023-06-13 #> 5         P01         108           94     4 2023-10-24     2023-06-13 #> 6         P01          31           70    12 2023-11-11     2023-06-13 #> 7         P01          84           79    13 2024-02-29     2023-06-13 #> 8         P01          91           43     8 2024-04-03     2023-06-13 #> 9         P01          72           72    11 2024-05-12     2023-06-13 #> 10        P02          94           37     4 2023-07-19     2024-01-04 #> 11        P02          54           57    10 2023-08-17     2024-01-04 #> 12        P02          99           92    13 2023-12-10     2024-01-04 #> 13        P02          66           11     6 2024-05-08     2024-01-04 #> 14        P02         140           84     9 2024-05-24     2024-01-04 #> 15        P02         143           44    11 2024-06-17     2024-01-04 #> 16        P02         125           77     8 2024-09-13     2024-01-04 #> 17        P02          37           12    14 2024-10-29     2024-01-04 #> 18        P02          62           47     5 2024-12-26     2024-01-04 #> 19        P03          46           64     6 2023-02-07     2023-06-23 #> 20        P03         144           41    11 2023-02-15     2023-06-23 #> 21        P03         130           78    12 2023-06-05     2023-06-23 #> 22        P03         126           45     8 2023-10-04     2023-06-23 #> 23        P03          42           20     4 2023-10-23     2023-06-23 #> 24        P03         131           42    13 2023-11-12     2023-06-23 #> 25        P03          62           16     9 2024-03-22     2023-06-23 #> 26        P03         106           32    14 2024-03-29     2023-06-23 #> 27        P03         111           43     7 2024-05-09     2023-06-23 #>    days_difference     time #> 1        -171 days baseline #> 2         -31 days baseline #> 3         -21 days baseline #> 4         116 days     6mth #> 5         133 days     6mth #> 6         151 days     6mth #> 7         261 days    12mth #> 8         295 days    12mth #> 9         334 days    12mth #> 10       -169 days baseline #> 11       -140 days baseline #> 12        -25 days baseline #> 13        125 days     6mth #> 14        141 days     6mth #> 15        165 days     6mth #> 16        253 days    12mth #> 17        299 days    12mth #> 18        357 days    12mth #> 19       -136 days baseline #> 20       -128 days baseline #> 21        -18 days baseline #> 22        103 days     6mth #> 23        122 days     6mth #> 24        142 days     6mth #> 25        273 days    12mth #> 26        280 days    12mth #> 27        321 days    12mth  # Extract readings ---------------------------------------------------------- ## 1. Baseline reading: latest reading in \"-180 days <= days_difference <= 0 days\" ## 2. 6-month reading: latest reading in \"100 days <= days_difference <= 180 days\" ## 3. 12-month reading: latest reading in \"240 days <= days_difference <= 360 days\" df_master %>%   # Blood pressure   extract_reading_from_interval(     list(       ID = \"patient_id\",       index_date = \"enrolment_date\"     ),     df_long,     list(       reading_date = \"visit_date\",       reading = c(\"bp_systolic\", \"bp_diastolic\")     ),     list(       baseline = c(-180, 0),       \"6mth\" = c(100, 180),       \"12mth\" = c(240, 360)     )   ) %>%   # HbA1c   extract_reading_from_interval(     list(       ID = \"patient_id\",       index_date = \"enrolment_date\"     ),     df_long,     list(       reading_date = \"visit_date\",       reading = \"hba1c\"     ),     list(       baseline = c(-180, 0),       \"6mth\" = c(100, 180),       \"12mth\" = c(240, 360)     )   ) %>%   print() #> <enrolment_date> is dropped from df_long, #> instead it will be taken from df_master #> <enrolment_date> is dropped from df_long, #> instead it will be taken from df_master #>   patient_id enrolment_date bp_systolic_date_baseline bp_systolic_baseline #> 1        P01     2023-06-13                2023-05-23                   53 #> 2        P02     2024-01-04                2023-12-10                   99 #> 3        P03     2023-06-23                2023-06-05                  130 #>   bp_diastolic_baseline bp_systolic_date_6mth bp_systolic_6mth #> 1                    14            2023-11-11               31 #> 2                    92            2024-06-17              143 #> 3                    78            2023-11-12              131 #>   bp_diastolic_6mth bp_systolic_date_12mth bp_systolic_12mth bp_diastolic_12mth #> 1                70             2024-05-12                72                 72 #> 2                44             2024-12-26                62                 47 #> 3                42             2024-05-09               111                 43 #>   hba1c_date_baseline hba1c_baseline hba1c_date_6mth hba1c_6mth #> 1          2023-05-23              6      2023-11-11         12 #> 2          2023-12-10             13      2024-06-17         11 #> 3          2023-06-05             12      2023-11-12         13 #>   hba1c_date_12mth hba1c_12mth #> 1       2024-05-12          11 #> 2       2024-12-26           5 #> 3       2024-05-09           7"},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ezyr: Helper Function Toolkit That Makes Data Operations Easier — ezyr-package","title":"ezyr: Helper Function Toolkit That Makes Data Operations Easier — ezyr-package","text":"package contains helper functions make easier handle, analyse, present data.","code":""},{"path":[]},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ezyr: Helper Function Toolkit That Makes Data Operations Easier — ezyr-package","text":"Maintainer: Jeremy Lew first@example.com","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_read_rds.html","id":null,"dir":"Reference","previous_headings":"","what":"Read encrypted RDS file — ezyr_read_rds","title":"Read encrypted RDS file — ezyr_read_rds","text":"ezyr_read_rds reads data encrypted RDS file.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_read_rds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read encrypted RDS file — ezyr_read_rds","text":"","code":"ezyr_read_rds(filepath, key)"},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_read_rds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read encrypted RDS file — ezyr_read_rds","text":"filepath (character) Filepath encrypted RDS file key (cyphr_key) Sodium key obtained invoking ask_for_key","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_read_rds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read encrypted RDS file — ezyr_read_rds","text":"Decrypted data encrypted RDS file","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_read_rds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read encrypted RDS file — ezyr_read_rds","text":"","code":"library(diffdf)  # Create random dataframe for illustration purpose set.seed(123) df <- data.frame(   col1 = sample(letters, 10, replace = TRUE), # Random characters   col2 = round(runif(10, min = 1, max = 100), 0), # Random integers between 1 and 100   col3 = runif(10, min = 0, max = 1) # Random floats between 0 and 1 )  # Get a sodium key key <- ask_for_key(\"my_password\")  # Save RDS file in temp directory filepath <- file.path(tempdir(), \"file1.rds\") ezyr_save_rds(df, filepath, key) print(list.files(tempdir(), pattern = \"\\\\.rds$\")) #> [1] \"file1.rds\"  # Read the RDS file back df_readback <- ezyr_read_rds(filepath, key)  # Compare the read back RDS file with original diffdf(base = df, compare = df_readback) #> No issues were found!  # Delete the saved RDS file in temp directory unlink(filepath) print(list.files(tempdir(), pattern = \"\\\\.rds$\")) #> character(0)"},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_save_rds.html","id":null,"dir":"Reference","previous_headings":"","what":"Save dataframe to an encrypted RDS file — ezyr_save_rds","title":"Save dataframe to an encrypted RDS file — ezyr_save_rds","text":"ezyr_save_rds saves dataframe RDS file encrypts sodium symmetric key.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_save_rds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save dataframe to an encrypted RDS file — ezyr_save_rds","text":"","code":"ezyr_save_rds(df, filepath, key)"},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_save_rds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save dataframe to an encrypted RDS file — ezyr_save_rds","text":"df (data.frame) dataframe want save rds format filepath (character) Filepath save RDS file key (cyphr_key) Sodium key obtained invoking ask_for_key","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_save_rds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save dataframe to an encrypted RDS file — ezyr_save_rds","text":"(data.frame) Original input dataframe","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/ezyr_save_rds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save dataframe to an encrypted RDS file — ezyr_save_rds","text":"","code":"library(diffdf)  # Create random dataframe for illustration purpose set.seed(123) df <- data.frame(   col1 = sample(letters, 10, replace = TRUE), # Random characters   col2 = round(runif(10, min = 1, max = 100), 0), # Random integers between 1 and 100   col3 = runif(10, min = 0, max = 1) # Random floats between 0 and 1 )  # Get a sodium key key <- ask_for_key(\"my_password\")  # Save RDS file in temp directory filepath <- file.path(tempdir(), \"file1.rds\") ezyr_save_rds(df, filepath, key) print(list.files(tempdir(), pattern = \"\\\\.rds$\")) #> [1] \"file1.rds\"  # Read the RDS file back df_readback <- ezyr_read_rds(filepath, key)  # Compare the read back RDS file with original diffdf(base = df, compare = df_readback) #> No issues were found!  # Delete the saved RDS file in temp directory unlink(filepath) print(list.files(tempdir(), pattern = \"\\\\.rds$\")) #> character(0)"},{"path":"https://jeremylew.github.io/ezyr/reference/format_p_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Format p-value — format_p_value","title":"Format p-value — format_p_value","text":"format_p_value converts p-values raw numeric form string presenting tables.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/format_p_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format p-value — format_p_value","text":"","code":"format_p_value(p_value)"},{"path":"https://jeremylew.github.io/ezyr/reference/format_p_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format p-value — format_p_value","text":"p_value (numeric numeric vector) p-value","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/format_p_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format p-value — format_p_value","text":"(character character vector) formatted p-value","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/format_p_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format p-value — format_p_value","text":"","code":"format_p_value(0.0001) #> [1] \"<0.001\" format_p_value(0.0086) #> [1] \"0.009\" format_p_value(0.0097) #> [1] \"0.01\" format_p_value(0.0456) #> [1] \"0.046\" format_p_value(0.0495) #> [1] \"0.0495\"  # Rounding follows IEEE 754 standard so rounding of 5 may not be up format_p_value(0.0085) #> [1] \"0.009\" format_p_value(0.055) #> [1] \"0.06\""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Get presentation template for a generalised linear model — get_presentation_template_glm","title":"Get presentation template for a generalised linear model — get_presentation_template_glm","text":"get_presentation_template_glm creates data.frame template lays variables model e.g. levels factor variable.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get presentation template for a generalised linear model — get_presentation_template_glm","text":"","code":"get_presentation_template_glm(model)"},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get presentation template for a generalised linear model — get_presentation_template_glm","text":"model (glm object) stats::glm model object","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get presentation template for a generalised linear model — get_presentation_template_glm","text":"(data.frame) template left join unto present regression results","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get presentation template for a generalised linear model — get_presentation_template_glm","text":"get_presentation_template_glm incorporated tabulate_glm_result, create table GLM results presentation Rmarkdown document.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get presentation template for a generalised linear model — get_presentation_template_glm","text":"","code":"library(dplyr) if (require(\"mlbench\") & require(\"forcats\")) {   data(BostonHousing2, package = \"mlbench\")    glm(medv ~ crim + zn + indus + town + rm + age + dis,     data = BostonHousing2 %>%       filter(town %in% c(         \"Newton\", \"Boston South Boston\", \"Boston Roxbury\",         \"Somerville\", \"Boston Savin Hill\", \"Cambridge\"       )) %>%       dplyr::mutate_at(\"town\", forcats::fct_drop),     family = gaussian(link = \"identity\")   ) %>%     get_presentation_template_glm() } #> Loading required package: mlbench #> Loading required package: forcats #>          variable_name   var0                     var #> 1                 crim header                    crim #> 2                   zn header                      zn #> 3                indus header                   indus #> 4                 town header                    <NA> #> 5       Boston Roxbury    Ref                    <NA> #> 6    Boston Savin Hill   <NA>   townBoston Savin Hill #> 7  Boston South Boston   <NA> townBoston South Boston #> 8            Cambridge   <NA>           townCambridge #> 9               Newton   <NA>              townNewton #> 10          Somerville   <NA>          townSomerville #> 11                  rm header                      rm #> 12                 age header                     age #> 13                 dis header                     dis"},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_mlogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Get presentation template for a multinomial logistic regression model — get_presentation_template_mlogit","title":"Get presentation template for a multinomial logistic regression model — get_presentation_template_mlogit","text":"get_presentation_template_mlogit creates data.frame template lays variables model.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_mlogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get presentation template for a multinomial logistic regression model — get_presentation_template_mlogit","text":"","code":"get_presentation_template_mlogit(model, data_labels = NULL)"},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_mlogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get presentation template for a multinomial logistic regression model — get_presentation_template_mlogit","text":"model (mlogit object) mlogit::mlogit model object data_labels (list) named list labels names: variable names values: labels labels set labelled package, list obtained invoking labelled::var_label()","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_mlogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get presentation template for a multinomial logistic regression model — get_presentation_template_mlogit","text":"(data.frame) Table multinomial logistic regression results","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/get_presentation_template_mlogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get presentation template for a multinomial logistic regression model — get_presentation_template_mlogit","text":"","code":"library(mlogit) #> Loading required package: dfidx #>  #> Attaching package: ‘dfidx’ #> The following object is masked from ‘package:stats’: #>  #>     filter data(iris)  # Run a multinomial logistic regression on iris dataset --------------------- mlogit(Species ~ 1 | Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,   data = mlogit.data(     iris %>%       mutate(Petal.Length = ifelse(         Petal.Length < 2.5,         \"Petal length < 2.5\",         \"Petal length >= 2.5\"       ) %>%         forcats::fct_relevel(\"Petal length < 2.5\", \"Petal length >= 2.5\")),     choice = \"Species\",     shape = \"wide\"   ),   reflevel = \"setosa\",   na.action = na.omit ) %>%   get_presentation_template_mlogit() #>         variable_name   var0                             var #> 1        Sepal.Length header                    Sepal.Length #> 2         Sepal.Width header                     Sepal.Width #> 3        Petal.Length header                            <NA> #> 4  Petal length < 2.5    Ref                            <NA> #> 5 Petal length >= 2.5   <NA> Petal.LengthPetal length >= 2.5 #> 6         Petal.Width header                     Petal.Width  # Run a multinomial logistic regression on labelled iris dataset ------------ labels <- list(   Sepal.Length = \"Sepal length\",   Sepal.Width = \"Sepal width\",   Petal.Length = \"Petal length\",   Petal.Width = \"Petal width\" ) labelled::var_label(iris) <- labels mlogit(Species ~ 1 | Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,   data = mlogit.data(     iris %>%       mutate(Petal.Length = ifelse(         Petal.Length < 2.5,         \"Petal length < 2.5\",         \"Petal length >= 2.5\"       ) %>%         forcats::fct_relevel(\"Petal length < 2.5\", \"Petal length >= 2.5\")),     choice = \"Species\",     shape = \"wide\"   ),   reflevel = \"setosa\",   na.action = na.omit ) %>%   get_presentation_template_mlogit(data_labels = labelled::var_label(iris)) #>         variable_name   var0                             var #> 1        Sepal length header                    Sepal.Length #> 2         Sepal width header                     Sepal.Width #> 3        Petal length header                            <NA> #> 4  Petal length < 2.5    Ref                            <NA> #> 5 Petal length >= 2.5   <NA> Petal.LengthPetal length >= 2.5 #> 6         Petal width header                     Petal.Width"},{"path":"https://jeremylew.github.io/ezyr/reference/label_ix_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Label prefixed or suffixed dataframe columns — label_ix_columns","title":"Label prefixed or suffixed dataframe columns — label_ix_columns","text":"label_ix_columns adds labels column(s) data.frame particular prefix/suffix specified, copying labels corresponding columns without prefix/suffix. labels added labelled::var_label().","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/label_ix_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label prefixed or suffixed dataframe columns — label_ix_columns","text":"","code":"label_ix_columns(df, pattern, suffix = TRUE)"},{"path":"https://jeremylew.github.io/ezyr/reference/label_ix_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label prefixed or suffixed dataframe columns — label_ix_columns","text":"df (data.frame) data form data frame pattern (character) regex pattern identify prefix/suffix suffix (logical) TRUE pattern suffix. FALSE pattern prefix","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/label_ix_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label prefixed or suffixed dataframe columns — label_ix_columns","text":"(data.frame) data new labels added","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/label_ix_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Label prefixed or suffixed dataframe columns — label_ix_columns","text":"","code":"library(labelled)  # Example of suffix --------------------------------------------------------- df <- data.frame(   sex = sample(1:2, 5, replace = TRUE),   race = sample(1:4, 5, replace = TRUE) ) df$sex.factor <- c(\"Female\", \"Male\")[df$sex] df$race.factor <- c(\"Chinese\", \"Malay\", \"Indian\", \"Others\")[df$race]  # Set labels labels <- list(   sex = \"Sex\",   race = \"Race\" ) var_label(df) <- labels  # Get labels after label_ix_columns() var_label(label_ix_columns(df, \".factor\", suffix = TRUE)) #> $sex #> [1] \"Sex\" #>  #> $race #> [1] \"Race\" #>  #> $sex.factor #> [1] \"Sex\" #>  #> $race.factor #> [1] \"Race\" #>   # Example of prefix --------------------------------------------------------- df <- data.frame(   sex = sample(1:2, 5, replace = TRUE),   race = sample(1:4, 5, replace = TRUE) ) df$fct_sex <- c(\"Female\", \"Male\")[df$sex] df$fct_race <- c(\"Chinese\", \"Malay\", \"Indian\", \"Others\")[df$race]  # Set labels labels <- list(   sex = \"Sex\",   race = \"Race\" ) var_label(df) <- labels  # Get labels after label_ix_columns() var_label(label_ix_columns(df, \"fct_\", suffix = FALSE)) #> $sex #> [1] \"Sex\" #>  #> $race #> [1] \"Race\" #>  #> $fct_sex #> [1] \"Sex\" #>  #> $fct_race #> [1] \"Race\" #>"},{"path":"https://jeremylew.github.io/ezyr/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://jeremylew.github.io/ezyr/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/plot_propensity_score_histogram.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a histogram from a MatchIt object — plot_propensity_score_histogram","title":"Plot a histogram from a MatchIt object — plot_propensity_score_histogram","text":"plot_propensity_score_histogram plots mirrored histogram enables visual inspection distribution propensity scores treatment vs control group.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/plot_propensity_score_histogram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a histogram from a MatchIt object — plot_propensity_score_histogram","text":"","code":"plot_propensity_score_histogram(   matchit_obj,   trt_control_var,   trt_label,   control_label,   is_after_matching = TRUE,   num_bins = 30 )"},{"path":"https://jeremylew.github.io/ezyr/reference/plot_propensity_score_histogram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a histogram from a MatchIt object — plot_propensity_score_histogram","text":"matchit_obj (matchit object) MatchIt::matchit object MatchIt R package trt_control_var (quosure) variable stores treatment/control grouping trt_label (character) value treatment group trt_control_var (e.g. video_consult_grp) control_label (character) value control group trt_control_var (e.g. face_to_face_grp) is_after_matching (logical) TRUE -matching plot, FALSE -matching plot num_bins (numeric) number bins histogram","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/plot_propensity_score_histogram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a histogram from a MatchIt object — plot_propensity_score_histogram","text":"ggplot object","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/plot_propensity_score_histogram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a histogram from a MatchIt object — plot_propensity_score_histogram","text":"","code":"library(MatchIt)  MatchIt::matchit(   treat ~ age + educ + race + married + nodegree + re78,   data = lalonde %>% dplyr::mutate(trt_control = ifelse(treat == 1, \"trt\", \"control\")),   method = \"nearest\",   ratio = 2 ) %>%   plot_propensity_score_histogram(trt_control, \"trt\", \"control\",     is_after_matching = TRUE, num_bins = 30   )"},{"path":"https://jeremylew.github.io/ezyr/reference/rename_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename column names — rename_colnames","title":"Rename column names — rename_colnames","text":"rename_colnames cleans column names raw data frame make.names, replaces whitespaces separator choice converts lower case.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/rename_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename column names — rename_colnames","text":"","code":"rename_colnames(df, separator = \"_\", add_labels = TRUE)"},{"path":"https://jeremylew.github.io/ezyr/reference/rename_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename column names — rename_colnames","text":"df (data.frame) data form data frame separator (character) Separator replace whitespaces add_labels (logical) TRUE want original column names used labels, FALSE otherwise","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/rename_colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename column names — rename_colnames","text":"(data.frame) data cleaned column names","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/rename_colnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rename column names — rename_colnames","text":"","code":"if (require(\"tibble\")) {   print(\"Original data\")   data <- tibble::tibble(     \"Column A!!!\" = sample(1:100, 5, replace = TRUE),     \"Column - 2;\" = runif(5, min = 0, max = 1),     \"Column: (3)\" = sample(letters, 5, replace = TRUE),     \"<Column 4...>\" = sample(c(TRUE, FALSE), 5, replace = TRUE)   )   data %>% print()    print(\"Data after renaming columns\")   data %>%     rename_colnames() %>%     print() } #> Loading required package: tibble #> [1] \"Original data\" #> # A tibble: 5 × 4 #>   `Column A!!!` `Column - 2;` `Column: (3)` `<Column 4...>` #>           <int>         <dbl> <chr>         <lgl>           #> 1            53         0.128 h             TRUE            #> 2             7         0.753 l             TRUE            #> 3            53         0.895 m             TRUE            #> 4            27         0.374 r             FALSE           #> 5            96         0.665 a             TRUE            #> [1] \"Data after renaming columns\" #> # A tibble: 5 × 4 #>   column_a column_2 column_3 x_column_4 #>      <int>    <dbl> <chr>    <lgl>      #> 1       53    0.128 h        TRUE       #> 2        7    0.753 l        TRUE       #> 3       53    0.895 m        TRUE       #> 4       27    0.374 r        FALSE      #> 5       96    0.665 a        TRUE"},{"path":"https://jeremylew.github.io/ezyr/reference/safe_left_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Safe left join — safe_left_join","title":"Safe left join — safe_left_join","text":"safe_left_join wrapper around dplyr::left_join additional check additional rows joined unto left data frame.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/safe_left_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Safe left join — safe_left_join","text":"","code":"safe_left_join(left_df, right_df, ...)"},{"path":"https://jeremylew.github.io/ezyr/reference/safe_left_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Safe left join — safe_left_join","text":"left_df (data.frame) Left data frame left join right_df (data.frame) Right data frame join unto left data frame ... (ellipsis) Extra arguments pass dplyr::left_join","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/safe_left_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Safe left join — safe_left_join","text":"(data.frame) left_df, left data frame","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/safe_left_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Safe left join — safe_left_join","text":"","code":"# Left table ---------------------------------------------------------------- left_table <- data.frame(   ID = sprintf(     \"%s%s\",     sample(1000:2000, 5, replace = TRUE),     sample(letters, 5, replace = TRUE)   ),   column_b = runif(5, min = 0, max = 1),   column_c = sample(letters, 5, replace = TRUE) ) print(left_table) #>      ID  column_b column_c #> 1 1462p 0.1028646        q #> 2 1040t 0.4348927        v #> 3 1430f 0.9849570        r #> 4 1089k 0.8930511        q #> 5 1315h 0.8864691        b  # Right table --------------------------------------------------------------- right_table <- data.frame(   ID = left_table$ID,   column_d = runif(5, min = 10, max = 50) ) print(right_table) #>      ID column_d #> 1 1462p 22.81493 #> 2 1040t 17.50764 #> 3 1430f 41.29177 #> 4 1089k 13.74380 #> 5 1315h 28.67116  # Left table has same row count after join ---------------------------------- left_table %>%   safe_left_join(right_table, by = \"ID\") %>%   print() #>      ID  column_b column_c column_d #> 1 1462p 0.1028646        q 22.81493 #> 2 1040t 0.4348927        v 17.50764 #> 3 1430f 0.9849570        r 41.29177 #> 4 1089k 0.8930511        q 13.74380 #> 5 1315h 0.8864691        b 28.67116  # Right table with duplicated ID -------------------------------------------- right_table2 <- rbind(right_table, data.frame(   ID = right_table[3:4, \"ID\"],   column_d = runif(2, min = 10, max = 50) )) print(right_table2) #>      ID column_d #> 1 1462p 22.81493 #> 2 1040t 17.50764 #> 3 1430f 41.29177 #> 4 1089k 13.74380 #> 5 1315h 28.67116 #> 6 1430f 30.46022 #> 7 1089k 33.99956  # Left table has more rows after join --------------------------------------- try(   left_table %>%     safe_left_join(right_table2, by = \"ID\") %>%     print() ) #> Error : Row count after join not equals row count before join"},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_glm_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Tabulate GLM result — tabulate_glm_result","title":"Tabulate GLM result — tabulate_glm_result","text":"tabulate_glm_result tabulates GLM results presentation Rmarkdown document.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_glm_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tabulate GLM result — tabulate_glm_result","text":"","code":"tabulate_glm_result(model, conf_lvl = 0.95, exponentiate = FALSE, num_dp = 2)"},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_glm_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tabulate GLM result — tabulate_glm_result","text":"model (glm object) stats::glm model object conf_lvl (numeric) Confidence level. default value 0.95 95% confidence level. default, summary.glm function R computes p-values using Wald method. consistent, compute confidence intervals using Wald method via stats::confint.default. See discussion post exponentiate (logical) TRUE beta-coefficients exponentiated expressed odds ratios. TRUE, confidence intervals also exponentiated correspondingly num_dp (numeric) Number decimal places present beta coefficients/odds ratios confidence intervals","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_glm_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tabulate GLM result — tabulate_glm_result","text":"(data.frame) Table GLM results","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_glm_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tabulate GLM result — tabulate_glm_result","text":"","code":"library(dplyr) if (require(\"mlbench\") & require(\"forcats\")) {   data(BostonHousing2, package = \"mlbench\")    glm(medv ~ crim + town + rm + age + dis,     data = BostonHousing2 %>%       filter(town %in% c(         \"Newton\", \"Boston South Boston\", \"Boston Roxbury\",         \"Somerville\", \"Boston Savin Hill\", \"Cambridge\"       )) %>%       dplyr::mutate_at(\"town\", forcats::fct_drop),     family = gaussian(link = \"identity\")   ) %>%     tabulate_glm_result() } #>          variable_name   var0                     var        beta  std_error #> 1                 crim header                    crim  0.03281571 0.04684588 #> 2                 town header                    <NA>          NA         NA #> 3       Boston Roxbury    Ref                    <NA>          NA         NA #> 4    Boston Savin Hill   <NA>   townBoston Savin Hill  0.15680129 1.51329455 #> 5  Boston South Boston   <NA> townBoston South Boston -0.34069764 1.67473462 #> 6            Cambridge   <NA>           townCambridge 13.31944678 1.56165139 #> 7               Newton   <NA>              townNewton  9.49983453 2.72208844 #> 8           Somerville   <NA>          townSomerville  7.47983762 1.81927838 #> 9                   rm header                      rm  9.23141134 0.68872082 #> 10                 age header                     age -0.09300762 0.04381661 #> 11                 dis header                     dis  0.69699530 1.58478814 #>       t_value      p_value   CI_lbound    CI_ubound          Beta (95% CI) #> 1   0.7005037 4.851192e-01 -0.05900053  0.124631953   0.03 (-0.06 to 0.12) #> 2          NA           NA          NA           NA                   <NA> #> 3          NA           NA          NA           NA                   <NA> #> 4   0.1036158 9.176664e-01 -2.80920153  3.122804112   0.16 (-2.81 to 3.12) #> 5  -0.2034338 8.391788e-01 -3.62311718  2.941721896  -0.34 (-3.62 to 2.94) #> 6   8.5290781 9.987464e-14 10.25866629 16.380227273 13.32 (10.26 to 16.38) #> 7   3.4899066 7.006615e-04  4.16463924 14.835029830   9.50 (4.16 to 14.84) #> 8   4.1114311 7.690232e-05  3.91411752 11.045557718   7.48 (3.91 to 11.05) #> 9  13.4037060 1.022210e-24  7.88154334 10.581279333   9.23 (7.88 to 10.58) #> 10 -2.1226567 3.606770e-02 -0.17888660 -0.007128644 -0.09 (-0.18 to -0.01) #> 11  0.4398035 6.609583e-01 -2.40913238  3.803122970   0.70 (-2.41 to 3.80) #>    p_value_ #> 1      0.49 #> 2      <NA> #> 3      <NA> #> 4      0.92 #> 5      0.84 #> 6    <0.001 #> 7    <0.001 #> 8    <0.001 #> 9    <0.001 #> 10     0.04 #> 11     0.66"},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_mlogit_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Tabulate multinomial logistic regression result — tabulate_mlogit_result","title":"Tabulate multinomial logistic regression result — tabulate_mlogit_result","text":"tabulate_mlogit_result tabulates results multinomial logistic regression created running mlogit::mlogit.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_mlogit_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tabulate multinomial logistic regression result — tabulate_mlogit_result","text":"","code":"tabulate_mlogit_result(   model,   outcome_levels_2onwards,   data_labels = NULL,   num_dp = 2 )"},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_mlogit_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tabulate multinomial logistic regression result — tabulate_mlogit_result","text":"model (mlogit object) mlogit::mlogit model object outcome_levels_2onwards (character) character vector outcome levels, level 2 onwards outcome level 1 refers reference level (omitted) outcome levels 2 onwards refers outcome levels reference level results outcome levels tabulated order, left right data_labels (list) named list labels names: variable names values: labels labels set labelled package, list obtained invoking labelled::var_label() num_dp (numeric) Number decimal places present confidence intervals. Defaults 2 d.p.","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_mlogit_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tabulate multinomial logistic regression result — tabulate_mlogit_result","text":"(data.frame) Table multinomial logistic regression results","code":""},{"path":"https://jeremylew.github.io/ezyr/reference/tabulate_mlogit_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tabulate multinomial logistic regression result — tabulate_mlogit_result","text":"","code":"library(mlogit) data(iris)  # Run a multinomial logistic regression on iris dataset --------------------- mlogit(Species ~ 1 | Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,   data = mlogit.data(     iris %>%       mutate(Petal.Length = ifelse(         Petal.Length < 2.5,         \"Petal length < 2.5\",         \"Petal length >= 2.5\"       ) %>%         forcats::fct_relevel(\"Petal length < 2.5\", \"Petal length >= 2.5\")),     choice = \"Species\",     shape = \"wide\"   ),   reflevel = \"setosa\",   na.action = na.omit ) %>%   tabulate_mlogit_result(c(\"versicolor\", \"virginica\")) #>         variable_name   var0                             var #> 1        Sepal.Length header                    Sepal.Length #> 2         Sepal.Width header                     Sepal.Width #> 3        Petal.Length header                            <NA> #> 4  Petal length < 2.5    Ref                            <NA> #> 5 Petal length >= 2.5   <NA> Petal.LengthPetal length >= 2.5 #> 6         Petal.Width header                     Petal.Width #>                                   Variable.x     Beta.x Std. Error.x #> 1                    Sepal.Length:versicolor -0.5881255     5942.981 #> 2                     Sepal.Width:versicolor  2.4638702     7857.212 #> 3                                       <NA>         NA           NA #> 4                                       <NA>         NA           NA #> 5 Petal.LengthPetal length >= 2.5:versicolor 54.8338912    25059.441 #> 6                     Petal.Width:versicolor -8.9519115    13945.986 #>       z-value.x p_value.x CI_lower.x CI_upper.x odds_ratio.x    95% CI.x #> 1 -9.896137e-05 0.9999210          0        Inf 5.553673e-01 0.00 to Inf #> 2  3.135807e-04 0.9997498          0        Inf 1.175020e+01 0.00 to Inf #> 3            NA        NA         NA         NA           NA        <NA> #> 4            NA        NA         NA         NA           NA        <NA> #> 5  2.188153e-03 0.9982541          0        Inf 6.517130e+23 0.00 to Inf #> 6 -6.418988e-04 0.9994878          0        Inf 1.294894e-04 0.00 to Inf #>   p_value_.x                                Variable.y     Beta.y Std. Error.y #> 1       1.00                    Sepal.Length:virginica  0.7070037     5942.981 #> 2       1.00                     Sepal.Width:virginica -2.3594039     7857.212 #> 3       <NA>                                      <NA>         NA           NA #> 4       <NA>                                      <NA>         NA           NA #> 5       1.00 Petal.LengthPetal length >= 2.5:virginica 28.3797729    21485.755 #> 6       1.00                     Petal.Width:virginica  6.9707490    13945.986 #>       z-value.y p_value.y CI_lower.y CI_upper.y odds_ratio.y    95% CI.y #> 1  0.0001189645 0.9999051          0        Inf 2.027906e+00 0.00 to Inf #> 2 -0.0003002851 0.9997604          0        Inf 9.447652e-02 0.00 to Inf #> 3            NA        NA         NA         NA           NA        <NA> #> 4            NA        NA         NA         NA           NA        <NA> #> 5  0.0013208646 0.9989461          0        Inf 2.114359e+12 0.00 to Inf #> 6  0.0004998391 0.9996012          0        Inf 1.065020e+03 0.00 to Inf #>   p_value_.y #> 1       1.00 #> 2       1.00 #> 3       <NA> #> 4       <NA> #> 5       1.00 #> 6       1.00  # Run a multinomial logistic regression on labelled iris dataset ------------ labels <- list(   Sepal.Length = \"Sepal length\",   Sepal.Width = \"Sepal width\",   Petal.Length = \"Petal length\",   Petal.Width = \"Petal width\" ) labelled::var_label(iris) <- labels mlogit(Species ~ 1 | Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,   data = mlogit.data(     iris %>%       mutate(Petal.Length = ifelse(         Petal.Length < 2.5,         \"Petal length < 2.5\",         \"Petal length >= 2.5\"       ) %>%         forcats::fct_relevel(\"Petal length < 2.5\", \"Petal length >= 2.5\")),     choice = \"Species\",     shape = \"wide\"   ),   reflevel = \"setosa\",   na.action = na.omit ) %>%   tabulate_mlogit_result(c(\"versicolor\", \"virginica\"), data_labels = labelled::var_label(iris)) #>         variable_name   var0                             var #> 1        Sepal length header                    Sepal.Length #> 2         Sepal width header                     Sepal.Width #> 3        Petal length header                            <NA> #> 4  Petal length < 2.5    Ref                            <NA> #> 5 Petal length >= 2.5   <NA> Petal.LengthPetal length >= 2.5 #> 6         Petal width header                     Petal.Width #>                                   Variable.x     Beta.x Std. Error.x #> 1                    Sepal.Length:versicolor -0.5881255     5942.981 #> 2                     Sepal.Width:versicolor  2.4638702     7857.212 #> 3                                       <NA>         NA           NA #> 4                                       <NA>         NA           NA #> 5 Petal.LengthPetal length >= 2.5:versicolor 54.8338912    25059.441 #> 6                     Petal.Width:versicolor -8.9519115    13945.986 #>       z-value.x p_value.x CI_lower.x CI_upper.x odds_ratio.x    95% CI.x #> 1 -9.896137e-05 0.9999210          0        Inf 5.553673e-01 0.00 to Inf #> 2  3.135807e-04 0.9997498          0        Inf 1.175020e+01 0.00 to Inf #> 3            NA        NA         NA         NA           NA        <NA> #> 4            NA        NA         NA         NA           NA        <NA> #> 5  2.188153e-03 0.9982541          0        Inf 6.517130e+23 0.00 to Inf #> 6 -6.418988e-04 0.9994878          0        Inf 1.294894e-04 0.00 to Inf #>   p_value_.x                                Variable.y     Beta.y Std. Error.y #> 1       1.00                    Sepal.Length:virginica  0.7070037     5942.981 #> 2       1.00                     Sepal.Width:virginica -2.3594039     7857.212 #> 3       <NA>                                      <NA>         NA           NA #> 4       <NA>                                      <NA>         NA           NA #> 5       1.00 Petal.LengthPetal length >= 2.5:virginica 28.3797729    21485.755 #> 6       1.00                     Petal.Width:virginica  6.9707490    13945.986 #>       z-value.y p_value.y CI_lower.y CI_upper.y odds_ratio.y    95% CI.y #> 1  0.0001189645 0.9999051          0        Inf 2.027906e+00 0.00 to Inf #> 2 -0.0003002851 0.9997604          0        Inf 9.447652e-02 0.00 to Inf #> 3            NA        NA         NA         NA           NA        <NA> #> 4            NA        NA         NA         NA           NA        <NA> #> 5  0.0013208646 0.9989461          0        Inf 2.114359e+12 0.00 to Inf #> 6  0.0004998391 0.9996012          0        Inf 1.065020e+03 0.00 to Inf #>   p_value_.y #> 1       1.00 #> 2       1.00 #> 3       <NA> #> 4       <NA> #> 5       1.00 #> 6       1.00"}]
